{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/baug8178/data/DHF1K/video/{:03d}.AVI\"\n",
    "output_path = \"/home/baug8178/data/DHF1K/boundary/{}_{}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage import color\n",
    "\n",
    "def Colour_Gradient(img):\n",
    "\n",
    "    \n",
    "    # Sobel Operator\n",
    "    h, w, d = img.shape\n",
    "\n",
    "    # define filters\n",
    "    horizontal = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])  # s2\n",
    "    vertical = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])  # s1\n",
    "\n",
    "    # define images with 0s\n",
    "    newgradientImage = np.zeros((h, w, d))\n",
    "\n",
    "    # offset by 1\n",
    "    for channel in range(d):\n",
    "        for i in range(1, h - 1):\n",
    "            for j in range(1, w - 1):\n",
    "                horizontalGrad = (horizontal[0, 0] * img[i - 1, j - 1, channel]) + \\\n",
    "                             (horizontal[0, 1] * img[i - 1, j, channel]) + \\\n",
    "                             (horizontal[0, 2] * img[i - 1, j + 1, channel]) + \\\n",
    "                             (horizontal[1, 0] * img[i, j - 1, channel]) + \\\n",
    "                             (horizontal[1, 1] * img[i, j, channel]) + \\\n",
    "                             (horizontal[1, 2] * img[i, j + 1, channel]) + \\\n",
    "                             (horizontal[2, 0] * img[i + 1, j - 1, channel]) + \\\n",
    "                             (horizontal[2, 1] * img[i + 1, j, channel]) + \\\n",
    "                             (horizontal[2, 2] * img[i + 1, j + 1, channel])\n",
    "\n",
    "                verticalGrad = (vertical[0, 0] * img[i - 1, j - 1, channel]) + \\\n",
    "                           (vertical[0, 1] * img[i - 1, j, channel]) + \\\n",
    "                           (vertical[0, 2] * img[i - 1, j + 1, channel]) + \\\n",
    "                           (vertical[1, 0] * img[i, j - 1, channel]) + \\\n",
    "                           (vertical[1, 1] * img[i, j, channel]) + \\\n",
    "                           (vertical[1, 2] * img[i, j + 1, channel]) + \\\n",
    "                           (vertical[2, 0] * img[i + 1, j - 1, channel]) + \\\n",
    "                           (vertical[2, 1] * img[i + 1, j, channel]) + \\\n",
    "                           (vertical[2, 2] * img[i + 1, j + 1, channel])\n",
    "\n",
    "                # Edge Magnitude\n",
    "                mag = np.sqrt(pow(horizontalGrad, 2.0) + pow(verticalGrad, 2.0))\n",
    "                # Avoid underflow: clip result\n",
    "                newgradientImage[i - 1, j - 1, channel] = mag\n",
    "\n",
    "    # now add the images r g and b\n",
    "    #rgb_edge = newgradientImage[:,:,0] + newgradientImage[:,:,1] + newgradientImage[:,:,2]\n",
    "    #gray_edge = np.dot(newgradientImage[...,:3], [0.299, 0.587, 0.114])\n",
    "    #print(newgradientImage.shape)\n",
    "    return 0.2989 * newgradientImage[:,:,0] + 0.5870 * newgradientImage[:,:,1] + 0.1140 * newgradientImage[:,:,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optFlow(frame1, frame2):\n",
    "   gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "   # Get the Shi Tomasi corners to use them as initial reference points\n",
    "   corners = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "   cornerColors = np.random.randint(0, 255, (corners.shape[0], 3))\n",
    "\n",
    "   # Create a mask image for drawing purposes\n",
    "   #mask = np.zeros_like(frame1)\n",
    "   hsvImg = np.zeros_like(frame1)\n",
    "   hsvImg[..., 1] = 255\n",
    "\n",
    "   # Play until the user decides to stop\n",
    "   while True:\n",
    "       # Save the previous frame data\n",
    "       previousGray = gray1\n",
    "       previousCorners = corners.reshape(-1, 1, 2)\n",
    "    \n",
    "       # Get the next frame\n",
    "       #ret , frame = cap.read()\n",
    "    \n",
    "       #if ret:\n",
    "       # Convert the frame to gray scale\n",
    "       gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "       # Calculate optical flow\n",
    "       flow = cv2.calcOpticalFlowFarneback(previousGray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "       #corners, st, err = cv2.calcOpticalFlowPyrLK(previousGray, gray, previousCorners, None, **lkParameters)\n",
    "        \n",
    "       # Obtain the flow magnitude and direction angle\n",
    "       mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        \n",
    "       # Update the color image\n",
    "       hsvImg[..., 0] = 0.5 * ang * 180 / np.pi\n",
    "       hsvImg[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "       rgbImg = cv2.cvtColor(hsvImg, cv2.COLOR_HSV2BGR)\n",
    "          \n",
    "       break\n",
    "        \n",
    "\n",
    "\n",
    "   # When everything is done, release the capture and close all windows\n",
    "   #cap.release()\n",
    "   \n",
    "   return rgbImg\n",
    "\n",
    "\n",
    "def boundary_map(frame_prev, frame_curr, bound_prev = None):\n",
    "    img = frame_prev\n",
    "    labels1 = slic(img, compactness=30, n_segments=1000)\n",
    "    out1  = color.label2rgb(labels1, img, kind='avg')\n",
    "    gray_edge_color = Colour_Gradient(out1)\n",
    "    \n",
    "    gray_edge_color_temp = Colour_Gradient(optFlow(frame_prev, frame_curr))\n",
    "    mean_avg = int(np.mean(gray_edge_color_temp)/2)\n",
    "    new_gray_color = np.zeros((gray_edge_color_temp.shape))\n",
    "    \n",
    "    mean_bound = 0\n",
    "    if bound_prev is not None:\n",
    "       mean_bound = np.mean(bound_prev)\n",
    "    \n",
    "    for i in range(0, frame_curr.shape[0]):\n",
    "        for j in range(0, frame_curr.shape[1]):\n",
    "              if (gray_edge_color_temp[i][j] > mean_avg):\n",
    "                  new_gray_color[i][j] = gray_edge_color_temp[i][j]\n",
    "              if (bound_prev is not None and bound_prev[i][j] < int(mean_bound)):\n",
    "                  bound_prev[i][j] = 0\n",
    "                 \n",
    "    if bound_prev is None:\n",
    "        boundary_map = (gray_edge_color  )   *  (1 - np.exp(-0.75 * new_gray_color)) \n",
    "    else:\n",
    "        boundary_map = ( (gray_edge_color  )   *  (1 - np.exp(-0.75 * new_gray_color)))  + (0.2 * bound_prev)\n",
    "        \n",
    "    return boundary_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing /home/baug8178/data/DHF1K/boundary/49_405.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_406.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_407.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_408.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_409.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_410.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_411.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_412.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_413.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_414.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_415.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_416.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_417.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_418.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_419.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_420.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_421.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_422.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_423.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_424.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_425.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_426.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_427.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_428.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_429.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_430.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_431.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_432.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_433.png\n",
      "writing /home/baug8178/data/DHF1K/boundary/49_434.png\n"
     ]
    }
   ],
   "source": [
    "def process_file(video_file):\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    ret, prev_frame = cap.read()\n",
    "    bound_prev = None\n",
    "    frame_count = 2\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if(ret == False):\n",
    "            break\n",
    "            \n",
    "        if file_no == 49 and frame_count < 405:\n",
    "          frame_count = frame_count + 1\n",
    "        else:\n",
    "          labels1 = slic(frame, compactness=30, n_segments=1000)\n",
    "          out1  = color.label2rgb(labels1, frame, kind='avg')\n",
    "          gray_edge = Colour_Gradient(out1)\n",
    "          bound_prev = boundary_map(prev_frame, frame, bound_prev)\n",
    "          output_file = output_path.format(file_no,frame_count )\n",
    "          print(\"writing {}\".format(output_file))\n",
    "          cv2.imwrite(output_file, bound_prev)\n",
    "          prev_frame = frame\n",
    "          frame_count = frame_count + 1\n",
    "    \n",
    "    cap.release()\n",
    "    return\n",
    "\n",
    "for file_no in range(49,1000):\n",
    "    \n",
    "    video_file = video_path.format(file_no)\n",
    "    \n",
    "    process_file(video_file)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_no in range(25,1000):\n",
    "    \n",
    "    video_file = video_path.format(file_no)\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    ret, prev_frame = cap.read()\n",
    "    bound_prev = None\n",
    "    frame_count = 2\n",
    "    \n",
    "    while(ret == True):\n",
    "        ret, frame = cap.read()\n",
    "        labels1 = slic(frame, compactness=30, n_segments=1000)\n",
    "        out1  = color.label2rgb(labels1, frame, kind='avg')\n",
    "        gray_edge = Colour_Gradient(out1)\n",
    "        bound_prev = boundary_map(prev_frame, frame, bound_prev)\n",
    "        output_file = output_path.format(file_no,frame_count )\n",
    "        print(\"writing {}\".format(output_file))\n",
    "        cv2.imwrite(output_file, bound_prev)\n",
    "        prev_frame = frame\n",
    "        frame_count = frame_count + 1\n",
    "        \n",
    "    cap.release()\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
