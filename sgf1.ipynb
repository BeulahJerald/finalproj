{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "#import glob\n",
    "import re\n",
    "import pims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/baug8178/data/DHF1K\"\n",
    "video_path = \"/home/baug8178/data/DHF1K/video/{:03d}.AVI\"\n",
    "annotation_path = \"/home/baug8178/data/DHF1K/annotation/{:04d}/maps/{:04d}.png\"\n",
    "video_train_frames = \"/home/baug8178/data/DHF1K/video_frames/*.jpg\"\n",
    "video_vali_frames = \"/home/baug8178/data/DHF1K/video_frames/vali/*.jpg\"\n",
    "video_test_frmaes = \"/home/baug8178/data/DHF1K/video_frames/test/*.jpg\"\n",
    "\n",
    "video_train_path = \"/home/baug8178/data/DHF1K/video_frames/{}_{}.jpg\"\n",
    "video_vali_path = \"/home/baug8178/data/DHF1K/video_frames/vali/{}_{}.jpg\"\n",
    "#video_test_path = \"/home/baug8178/data/DHF1K/video_frames/test/{}_{}.jpg\"\n",
    "dhf1k_filename = \".AVI\"\n",
    "train_num_files = 420\n",
    "val_num_files = 10\n",
    "batch_size = 8\n",
    "total_frames =  389592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "framesobj = []\n",
    "\n",
    "for file_no in range(1, train_num_files + 1):\n",
    "  video_file = video_path.format(file_no)\n",
    "  cap = cv2.VideoCapture(video_file)\n",
    "  length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  #print( length )\n",
    "\n",
    "  #framesobj.append (v)\n",
    "  [frames.append([file_no,i])  for i in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "frames = shuffle(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(batch_size):\n",
    "    \n",
    "    #number_of_batches  = (train_num_files - 1) / batch_size\n",
    "    counter = 0   \n",
    "    #read_size = batch_size\n",
    "    \n",
    "    while(1):\n",
    "        \n",
    "        read_size = min(batch_size, total_frames - counter)\n",
    "        train_x = np.empty((read_size, 360,640,3), dtype = np.int8)\n",
    "        train_y = np.empty((read_size, 360,640,1), dtype = np.int8)\n",
    "        \n",
    "        for i in range(read_size):\n",
    "        \n",
    "          video_file = video_path.format(frames[i][0])\n",
    "          v = pims.Video(video_file)\n",
    "          img = v[frames[i][1]]\n",
    "          train_x[i,...] = img[None]\n",
    "         \n",
    "          anno_train_file = annotation_path.format(int(frames[i][0]), int(frames[i][1]))\n",
    "          img = cv2.imread(anno_train_file,0)\n",
    "          img = img.reshape(img.shape[0],img.shape[1], 1)\n",
    "          train_y[i,...] = img[None]\n",
    "        \n",
    "        counter = counter + read_size\n",
    "        if counter >= total_frames:\n",
    "           counter = 0\n",
    "\n",
    "        yield train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_processing:\n",
    "    def __init__(self):\n",
    "        self.buffer_file = None\n",
    "        self.buffer_file_y = None\n",
    "        self.buffer_rem = 0\n",
    "        self.start_file_num = 1\n",
    "        return\n",
    "    \n",
    "    def read_videos(self,start_file_no , num_files):\n",
    "        frame_count = []\n",
    "        frames = []\n",
    "        for i in range(start_file_no , start_file_no + num_files):\n",
    "           count = 0\n",
    "           filename = video_path.format(i) \n",
    "           vidcap = cv2.VideoCapture(filename)\n",
    "           #print(filename)\n",
    "           success,image = vidcap.read()\n",
    "           while success:\n",
    "             frames.append(image)\n",
    "             success,image = vidcap.read()\n",
    "             count += 1\n",
    "        \n",
    "           frame_count.append(count)\n",
    "            \n",
    "\n",
    "        return np.array(frames), np.array(frame_count)\n",
    "    \n",
    "    def read_annotations(self,start_file_no , num_files,frame_count):\n",
    "        frames =[]\n",
    "        count_i = 0\n",
    "        for i in range(start_file_no , start_file_no + num_files):\n",
    "            #folder_path = \"annotation\\\\\"+\"{:04}\".format(i)+\"\\\\maps\\\\\"\n",
    "            \n",
    "            for j in range(1,frame_count[count_i]+ 1):\n",
    "                #print(j)\n",
    "                filename = annotation_path.format(i,j)\n",
    "                #print(filename)\n",
    "                frame = cv2.imread(filename, 0)\n",
    "                #print(frame.shape)\n",
    "                frames.append(frame)\n",
    "            count_i = count_i + 1\n",
    "         \n",
    "        frames = np.array(frames)\n",
    "        #print(frames.shape)\n",
    "        frames = frames.reshape((frames.shape[0], frames.shape[1], frames.shape[2],1))\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = data_processing()\n",
    "val_x, val_frame_count = dp.read_videos(421, val_num_files)\n",
    "val_y = dp.read_annotations(421, val_num_files, val_frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5300, 360, 640, 3)\n",
      "(5300, 360, 640, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "        \n",
    "print(val_x.shape) \n",
    "#print(len(train_frame_count))\n",
    "print(val_y.shape)\n",
    "\n",
    "\n",
    "val_x, val_y = shuffle(val_x, val_y, n_samples  = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baug8178/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import keras\n",
    "#import KerasD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Deconvolution2D,Convolution2D\n",
    "from keras.layers import UpSampling2D,Activation, Input, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "def norm_weights(n):\n",
    "    r = n / 2.0\n",
    "    xs = np.linspace(-r, r, n)\n",
    "    x, y = np.meshgrid(xs, xs)\n",
    "    w = np.exp(-0.5*(x**2 + y**2))\n",
    "    w /= w.sum()\n",
    "    return w\n",
    "\n",
    "def deconv(nb_filter, size, name):\n",
    "    upsample = UpSampling2D(size=(size, size))\n",
    "    s = 2 * size + 1\n",
    "    #w = norm_weights(s)[ :, :,np.newaxis, np.newaxis]\n",
    "    conv = Convolution2D(\n",
    "        nb_filter, (s, s),\n",
    "        name=name,\n",
    "        activation='linear',\n",
    "        bias=False,\n",
    "        border_mode='same')\n",
    "    return lambda x: conv(upsample(x))\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    input_tensor = Input(shape=( 360, 640, 3)) \n",
    "    #base_model = VGG16(weights='imagenet', include_top=False ,input_shape=(3, 360, 640))\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False ,input_tensor=input_tensor)\n",
    "\n",
    "    x = model_vgg16_conv.get_layer('block3_pool').output\n",
    "    #x = Conv2D(512, (5, 5), init='normal', activation='relu', border_mode='same', name='conv4')(x)\n",
    "    #x = Conv2D(512, (5, 5), init='normal', activation='relu', border_mode='same', name='conv5')(x)\n",
    "    #x = Conv2D(256, (7, 7), init='normal', activation='relu', border_mode='same', name='conv6')(x)\n",
    "    x = Convolution2D(128, (11, 11), init='normal', activation='relu', border_mode='same', name='conv7')(x)\n",
    "    x = Convolution2D(32 , (11, 11), init='normal', activation='relu', border_mode='same', name='conv8')(x)\n",
    "    x = Convolution2D(1 , (13, 13), init='normal', activation='relu', border_mode='same', name='conv9')(x)\n",
    "    x = deconv(1,8, 'deconv')(x)\n",
    "    output = Activation('sigmoid')(x)\n",
    "\n",
    "    model = Model(input=input_tensor, output=output )\n",
    "    model.summary()\n",
    "\n",
    "    for layer in model_vgg16_conv.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    adam = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001, amsgrad=False)\n",
    "    model.compile(optimizer=adam, loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 360, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 360, 640, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 360, 640, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 180, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 180, 320, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 180, 320, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 90, 160, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 90, 160, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 90, 160, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 90, 160, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 45, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 45, 80, 128)       3965056   \n",
      "_________________________________________________________________\n",
      "conv8 (Conv2D)               (None, 45, 80, 32)        495648    \n",
      "_________________________________________________________________\n",
      "conv9 (Conv2D)               (None, 45, 80, 1)         5409      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 360, 640, 1)       0         \n",
      "_________________________________________________________________\n",
      "deconv (Conv2D)              (None, 360, 640, 1)       289       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 360, 640, 1)       0         \n",
      "=================================================================\n",
      "Total params: 6,201,890\n",
      "Trainable params: 6,201,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baug8178/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (11, 11), activation=\"relu\", name=\"conv7\", padding=\"same\", kernel_initializer=\"normal\")`\n",
      "/home/baug8178/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (11, 11), activation=\"relu\", name=\"conv8\", padding=\"same\", kernel_initializer=\"normal\")`\n",
      "/home/baug8178/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (13, 13), activation=\"relu\", name=\"conv9\", padding=\"same\", kernel_initializer=\"normal\")`\n",
      "/home/baug8178/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (17, 17), name=\"deconv\", activation=\"linear\", padding=\"same\", use_bias=False)`\n",
      "/home/baug8178/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "sgf1model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1613/97533 [..............................] - ETA: 22:23:33 - loss: 2.9109"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "class MyCbk(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model, header):\n",
    "        self.model_to_save = model.layers[0]\n",
    "        self.header_name = header\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model_to_save.save(self.header_name + 'model_at_epoch_2_%d.h5' % epoch)\n",
    "        \n",
    "cbk = MyCbk(sgf1model,'sgf1model_')\n",
    "batch_size = 4\n",
    "sgf1model.fit_generator(myGenerator(batch_size), steps_per_epoch=(total_frames) / batch_size, epochs=20,\n",
    "                        verbose=1, callbacks=[cbk], validation_data=(val_x, val_y),\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
